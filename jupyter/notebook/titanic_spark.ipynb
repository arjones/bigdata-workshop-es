{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificaci칩n con data de hundimiento del Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraccion (Ejercicio 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_titanic_data(url, refresh_cache=False):\n",
    "    cache_fn = Path('titanic.csv')\n",
    "    if not cache_fn.exists() or refresh_cache:\n",
    "        print(\"Getting data\")\n",
    "        df = pd.read_csv(url)\n",
    "        df.to_csv(cache_fn, index=False)\n",
    "    else:\n",
    "        print(\"Using cache\")\n",
    "        df = pd.read_csv(cache_fn)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic3.csv'\n",
    "df_raw = extract_titanic_data(url)\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and holdout\n",
    "np.random.seed(1234)\n",
    "msk = np.random.rand(len(df_raw)) >= 0.3\n",
    "df_train = df_raw[msk]\n",
    "df_test = df_raw[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Primer preproceso / EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiene sentido dropear boat (y tambien body)\n",
    "survived_with_boat = len(df_train[(~df_train['boat'].isnull()) & (df_train['survived'] == 1)])\n",
    "survived = len(df_train[df_train['survived'] == 1])\n",
    "(survived_with_boat / survived) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s-%(name)s-%(levelname)s: %(message)s',\n",
    "    handlers=[logging.FileHandler('titanic.log'), logging.StreamHandler()],\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _drop_unusable_cols(df, cols=[]):\n",
    "    logger.info(\n",
    "        f\"Dropping the following {len(cols)} unusable columns:\\n\"\n",
    "        f\"{cols}\"\n",
    "    )\n",
    "    #df.drop(cols, axis=1, inplace=True)\n",
    "    df = df.drop(cols, axis=1)\n",
    "    logger.info(\n",
    "        f\"Remaining {len(df.columns)} columns:\\n {sorted(df.columns.tolist())}\"\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = _drop_unusable_cols(df_train, cols=['boat', 'body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns, df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = _drop_unusable_cols(df_test, cols=['boat', 'body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join train test\n",
    "df_train['train'] = True\n",
    "df_test['train'] = False\n",
    "df = pd.concat([df_train, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(df['sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "pd.value_counts(df['survived'], normalize=True).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA y Ejercicio 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.heatmap(df[['survived', 'age', 'parch', 'fare', 'sibsp']].corr(),\n",
    "                annot=True, fmt = \".2f\", cmap = \"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(df, col='survived')\n",
    "g = g.map(sns.distplot, 'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.kdeplot(df['age'][(df['survived'] == 0) & \n",
    "                             (df['age'].notnull())], color='Red', shade = True)\n",
    "g = sns.kdeplot(df['age'][(df['survived'] == 1) & \n",
    "                             (df['age'].notnull())], color='Blue', shade = True)\n",
    "g.set_xlabel('age')\n",
    "g.set_ylabel('Frequency')\n",
    "g = g.legend(['Not Survived', 'Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['fare'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fare'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['fare'].fillna(df['fare'].mean()).isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuci칩n de precio de boletos \n",
    "g = sns.distplot(df['fare'].fillna(df['fare'].mean()), color='m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['fare'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fare'] = df['fare'].map(lambda i: np.log(i) if i > 0 else 0)\n",
    "g = sns.distplot(df['fare'].fillna(df['fare'].mean()), color='m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.barplot(x='sex', y='survived', data=df)\n",
    "g = g.set_ylabel(\"Survival Probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['sex', 'survived']].groupby('sex').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.factorplot(x='pclass', y='survived', hue='sex', data=df,\n",
    "                   height=6, kind='bar')\n",
    "g = g.set_ylabels(\"survival probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4: Valores nulos y constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(df.isnull().mean() < 0.5).index.tolist()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _drop_nulls(df, max_null_prop=0.5):\n",
    "    logger.info(\n",
    "        f\"Dropping columns with null ratio greater than {max_null_prop * 100}%...\"\n",
    "    )\n",
    "    null_means = df.isnull().mean()\n",
    "    null_mask = null_means < max_null_prop\n",
    "    null_mask[[c for c in null_mask.index.tolist() if c in PROTECTED_COLS]] = True\n",
    "    drop_cols = null_mask[~null_mask].index.tolist()\n",
    "    logger.info(\n",
    "        f\"null proportions:\\n\"\n",
    "        f\"{null_means.loc[drop_cols].sort_values(ascending=False)}\"\n",
    "    )\n",
    "\n",
    "    logger.info(f\"Dropping the following {len(drop_cols)} columns:\\n {drop_cols}\")\n",
    "\n",
    "    df = df.drop(drop_cols, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROTECTED_COLS = ['survived', 'train']\n",
    "df = _drop_nulls(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _drop_std(df, min_std_dev=1.5e-2):\n",
    "    std_values = df.std()\n",
    "    low_variance_cols = std_values < min_std_dev\n",
    "    low_variance_cols = low_variance_cols.index[low_variance_cols].tolist()\n",
    "    low_variance_cols = [c for c in low_variance_cols if c not in PROTECTED_COLS]\n",
    "    logger.info(\n",
    "        f'Dropping the following {len(low_variance_cols)} columns '\n",
    "        f'due to low variance:\\n {low_variance_cols}'\n",
    "    )\n",
    "    df.drop(low_variance_cols, axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = _drop_std(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 1 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_typed_cols(df, col_type='cat'):\n",
    "    assert col_type in ('cat', 'num')\n",
    "    include = 'object' if col_type == 'cat' else [np.number]\n",
    "    typed_cols = [\n",
    "        c for c in df.select_dtypes(include=include).columns if c not in PROTECTED_COLS\n",
    "    ]\n",
    "    return typed_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_get_typed_cols(df, col_type='foo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = _get_typed_cols(df, col_type='num')\n",
    "cat_cols = _get_typed_cols(df, col_type='cat')\n",
    "num_cols, cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sex'].value_counts().index.to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fill_nulls(df):\n",
    "    for t in ['num', 'cat']:\n",
    "        cols = _get_typed_cols(df, col_type=t)\n",
    "        for c in cols:\n",
    "            if t == 'num':\n",
    "                df[c] = df[c].fillna(df[c].median())\n",
    "            else:\n",
    "                val_count = df[c].value_counts(dropna=True)\n",
    "                common_val = val_count.index.tolist()[0]\n",
    "                df[c] = df[c].fillna(common_val)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = _fill_nulls(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5: Ingenieria de Atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.name.str.split(',').str[-1].str.split('.').str[0].str.strip().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un nuevo atributo \"titulo\"\n",
    "df['title'] = df.name.str.split(',').str[-1].str.split('.').str[0].str.strip()\n",
    "df['title'] = df['title'].replace(\n",
    "    df.title.value_counts(dropna=False).index.tolist()[4:], 'other'\n",
    ")\n",
    "df['title'] = df['title'].replace(['Miss'], 'Mrs')\n",
    "df = df.drop(['name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.countplot(df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.factorplot(x='title',y='survived',data=df,kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['family_size'] = df['parch'] + df['sibsp'] + 1\n",
    "df['family_single'] = df['family_size'] == 1\n",
    "df['family_small'] = (df['family_size'] > 1) & (df['family_size'] <= 4)\n",
    "df['family_large'] = df['family_size'] > 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fsize in ['single', 'small', 'large']:\n",
    "    g = sns.factorplot(x=f'family_{fsize}',y='survived',data=df,kind=\"bar\")\n",
    "    g = g.set_ylabels(\"Survival Probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ticket.sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ticket prefix\n",
    "def extract_ticket_prefix(i):\n",
    "    if not i.isdigit() :\n",
    "        rv = i.replace('.',\"\").replace('/',\"\").strip().split(' ')[0]\n",
    "    else:\n",
    "        rv = 'X'\n",
    "    return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ticket'] = df['ticket'].apply(extract_ticket_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ticket.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 6: Fitteo de regresi칩n logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['home.dest'].value_counts().index.values[0: 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _encode_categorical(df, top=20):\n",
    "    logger.info(\"Filtering categorical columns top values...\")\n",
    "    cat_cols = _get_typed_cols(df, col_type='cat')\n",
    "    logger.info(f\"Categorical columns:\\n {cat_cols}\")\n",
    "\n",
    "    for c in cat_cols:\n",
    "        top_categories = df[c].value_counts().index.values[0:top]\n",
    "        logger.info(f\"Top categories for {c}:\\n {top_categories}\")\n",
    "        df[c] = df[c].where(df[c].isin(top_categories), other='OTHER')\n",
    "\n",
    "    logger.info(\"Getting dummies from top categories...\")\n",
    "    df = pd.get_dummies(df, columns=cat_cols, drop_first=False)\n",
    "    logger.info(\n",
    "        f\"{len(df.columns)} columns after dummies:\\n \" f\"{sorted(df.columns.tolist())}\"\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = _encode_categorical(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df['train']]\n",
    "df_test = df[~df['train']]\n",
    "y_train = df_train['survived']\n",
    "y_test = df_test['survived']\n",
    "X_train = df_train.drop(['survived', 'train'], axis=1)\n",
    "X_test = df_test.drop(['survived', 'train'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'age' in X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "y_pred_proba = lr.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_score = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score = metrics.f1_score(y_test, y_pred)\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = metrics.classification_report(y_test, y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 7: 치rboles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeClassifier()\n",
    "dt = dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "y_pred_proba = dt.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.plot_tree(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=5, n_jobs=-1, verbose=2,)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "y_pred_proba = rf.predict_proba(X_test)[:, 1]\n",
    "print(rf.score(X_train, y_train))\n",
    "print(rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "feat_import = list(\n",
    "zip(np.asanyarray(X_train.columns)[indices], importances[indices])\n",
    ")\n",
    "feat_import = pd.DataFrame(feat_import, columns=['feature', 'importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = feat_import[:20].plot(kind='bar')\n",
    "ax.set_xticklabels(feat_import[:20]['feature'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
