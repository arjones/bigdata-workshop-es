{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificaci√≥n con data de hundimiento del Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('pyspark-titanic').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.4'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = spark.read.csv('/dataset/titanic.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------------------+------+----+-----+-----+--------+--------+-------+--------+----+-----+--------------------+\n",
      "|pclass|survived|                name|   sex| age|sibsp|parch|  ticket|    fare|  cabin|embarked|boat| body|           home.dest|\n",
      "+------+--------+--------------------+------+----+-----+-----+--------+--------+-------+--------+----+-----+--------------------+\n",
      "|     1|       1|Allen, Miss. Elis...|female|29.0|    0|    0|   24160|211.3375|     B5|       S|   2| null|        St Louis, MO|\n",
      "|     1|       1|Allison, Master. ...|  male|0.92|    1|    2|  113781|  151.55|C22 C26|       S|  11| null|Montreal, PQ / Ch...|\n",
      "|     1|       0|Allison, Miss. He...|female| 2.0|    1|    2|  113781|  151.55|C22 C26|       S|null| null|Montreal, PQ / Ch...|\n",
      "|     1|       0|Allison, Mr. Huds...|  male|30.0|    1|    2|  113781|  151.55|C22 C26|       S|null|135.0|Montreal, PQ / Ch...|\n",
      "|     1|       0|Allison, Mrs. Hud...|female|25.0|    1|    2|  113781|  151.55|C22 C26|       S|null| null|Montreal, PQ / Ch...|\n",
      "|     1|       1| Anderson, Mr. Harry|  male|48.0|    0|    0|   19952|   26.55|    E12|       S|   3| null|        New York, NY|\n",
      "|     1|       1|Andrews, Miss. Ko...|female|63.0|    1|    0|   13502| 77.9583|     D7|       S|  10| null|          Hudson, NY|\n",
      "|     1|       0|Andrews, Mr. Thom...|  male|39.0|    0|    0|  112050|     0.0|    A36|       S|null| null|         Belfast, NI|\n",
      "|     1|       1|Appleton, Mrs. Ed...|female|53.0|    2|    0|   11769| 51.4792|   C101|       S|   D| null| Bayside, Queens, NY|\n",
      "|     1|       0|Artagaveytia, Mr....|  male|71.0|    0|    0|PC 17609| 49.5042|   null|       C|null| 22.0| Montevideo, Uruguay|\n",
      "+------+--------+--------------------+------+----+-----+-----+--------+--------+-------+--------+----+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dft.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pclass: string (nullable = true)\n",
      " |-- survived: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- sibsp: string (nullable = true)\n",
      " |-- parch: string (nullable = true)\n",
      " |-- ticket: string (nullable = true)\n",
      " |-- fare: string (nullable = true)\n",
      " |-- cabin: string (nullable = true)\n",
      " |-- embarked: string (nullable = true)\n",
      " |-- boat: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- home.dest: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dft.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = dft.withColumn('survived', dft['survived'].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pclass: string (nullable = true)\n",
      " |-- survived: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- sibsp: string (nullable = true)\n",
      " |-- parch: string (nullable = true)\n",
      " |-- ticket: string (nullable = true)\n",
      " |-- fare: string (nullable = true)\n",
      " |-- cabin: string (nullable = true)\n",
      " |-- embarked: string (nullable = true)\n",
      " |-- boat: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- home.dest: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dft.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|survived|\n",
      "+--------+\n",
      "|       1|\n",
      "|       1|\n",
      "|       0|\n",
      "|       0|\n",
      "|       0|\n",
      "+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dft.select('survived').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|survived|count|\n",
      "+--------+-----+\n",
      "|       1|  500|\n",
      "|       0|  809|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dft.groupBy('survived').count().orderBy('count').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraccion (Ejercicio 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_titanic_data(url, refresh_cache=False):\n",
    "    cache_fn = Path('/dataset/titanic_local.csv')\n",
    "    if not cache_fn.exists() or refresh_cache:\n",
    "        print(\"Getting data\")\n",
    "        df = pd.read_csv(url)\n",
    "        df.to_csv(cache_fn, index=False)\n",
    "    print(\"Using cache\")\n",
    "    df = spark.read.csv(str(cache_fn), header=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic3.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cache\n"
     ]
    }
   ],
   "source": [
    "df_raw = extract_titanic_data(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------------------+------+----+-----+-----+--------+--------+-------+--------+----+-----+--------------------+\n",
      "|pclass|survived|                name|   sex| age|sibsp|parch|  ticket|    fare|  cabin|embarked|boat| body|           home.dest|\n",
      "+------+--------+--------------------+------+----+-----+-----+--------+--------+-------+--------+----+-----+--------------------+\n",
      "|     1|       1|Allen, Miss. Elis...|female|29.0|    0|    0|   24160|211.3375|     B5|       S|   2| null|        St Louis, MO|\n",
      "|     1|       1|Allison, Master. ...|  male|0.92|    1|    2|  113781|  151.55|C22 C26|       S|  11| null|Montreal, PQ / Ch...|\n",
      "|     1|       0|Allison, Miss. He...|female| 2.0|    1|    2|  113781|  151.55|C22 C26|       S|null| null|Montreal, PQ / Ch...|\n",
      "|     1|       0|Allison, Mr. Huds...|  male|30.0|    1|    2|  113781|  151.55|C22 C26|       S|null|135.0|Montreal, PQ / Ch...|\n",
      "|     1|       0|Allison, Mrs. Hud...|female|25.0|    1|    2|  113781|  151.55|C22 C26|       S|null| null|Montreal, PQ / Ch...|\n",
      "|     1|       1| Anderson, Mr. Harry|  male|48.0|    0|    0|   19952|   26.55|    E12|       S|   3| null|        New York, NY|\n",
      "|     1|       1|Andrews, Miss. Ko...|female|63.0|    1|    0|   13502| 77.9583|     D7|       S|  10| null|          Hudson, NY|\n",
      "|     1|       0|Andrews, Mr. Thom...|  male|39.0|    0|    0|  112050|     0.0|    A36|       S|null| null|         Belfast, NI|\n",
      "|     1|       1|Appleton, Mrs. Ed...|female|53.0|    2|    0|   11769| 51.4792|   C101|       S|   D| null| Bayside, Queens, NY|\n",
      "|     1|       0|Artagaveytia, Mr....|  male|71.0|    0|    0|PC 17609| 49.5042|   null|       C|null| 22.0| Montevideo, Uruguay|\n",
      "+------+--------+--------------------+------+----+-----+-----+--------+--------+-------+--------+----+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pclass: string (nullable = true)\n",
      " |-- survived: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- sibsp: string (nullable = true)\n",
      " |-- parch: string (nullable = true)\n",
      " |-- ticket: string (nullable = true)\n",
      " |-- fare: string (nullable = true)\n",
      " |-- cabin: string (nullable = true)\n",
      " |-- embarked: string (nullable = true)\n",
      " |-- boat: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- home.dest: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1309"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "train_df, test_df = df_raw.randomSplit([0.7,0.3],seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.randomSplit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.rand?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "959"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import rand, when\n",
    "df_raw = df_raw.withColumn('train', when(rand(seed=1234) >= 0.3, True).otherwise(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|train|count|\n",
      "+-----+-----+\n",
      "| true|  886|\n",
      "|false|  423|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw.select('train').groupby('train').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- train: boolean (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw.select('train').printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_raw.filter(f.col('train') == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "949"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_raw.filter(f.col('train') != True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Primer preproceso / EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pclass: string (nullable = true)\n",
      " |-- survived: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- sibsp: string (nullable = true)\n",
      " |-- parch: string (nullable = true)\n",
      " |-- ticket: string (nullable = true)\n",
      " |-- fare: string (nullable = true)\n",
      " |-- cabin: string (nullable = true)\n",
      " |-- embarked: string (nullable = true)\n",
      " |-- boat: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- home.dest: string (nullable = true)\n",
      " |-- train: boolean (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Casteo de datos\n",
    "df_raw.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_cols(df, cols, new_type):\n",
    "  for col in cols: \n",
    "     df = df.withColumn(col, df[col].cast(new_type()))\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_cols = ['survived', 'sibsp', 'parch', 'body']\n",
    "float_cols = ['age', 'fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = cast_cols(df_raw, integer_cols, IntegerType)\n",
    "df_raw = cast_cols(df_raw, float_cols, DoubleType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pclass: string (nullable = true)\n",
      " |-- survived: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- sibsp: integer (nullable = true)\n",
      " |-- parch: integer (nullable = true)\n",
      " |-- ticket: string (nullable = true)\n",
      " |-- fare: double (nullable = true)\n",
      " |-- cabin: string (nullable = true)\n",
      " |-- embarked: string (nullable = true)\n",
      " |-- boat: string (nullable = true)\n",
      " |-- body: integer (nullable = true)\n",
      " |-- home.dest: string (nullable = true)\n",
      " |-- train: boolean (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.954"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survived_on_boat = df_raw.filter((f.col('boat').isNotNull()) & (f.col('survived') == 1)).count()\n",
    "survived = df_raw.filter(f.col('survived') == 1).count()\n",
    "survived_on_boat / survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s-%(name)s-%(levelname)s: %(message)s',\n",
    "    handlers=[logging.FileHandler('/dataset/titanic_spark.log'), logging.StreamHandler()],\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _drop_unusable_cols(df, cols=[]):\n",
    "    logger.info(\n",
    "        f\"Dropping the following {len(cols)} unusable columns:\\n\"\n",
    "        f\"{cols}\"\n",
    "    )\n",
    "    df = df.drop(*cols)\n",
    "    logger.info(\n",
    "        f\"Remaining {len(df.columns)} columns:\\n {sorted(df.columns)}\"\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-10 02:01:25,224-__main__-INFO: Dropping the following 3 unusable columns:\n",
      "['boat', 'body', 'train']\n",
      "2019-12-10 02:01:25,252-__main__-INFO: Remaining 12 columns:\n",
      " ['age', 'cabin', 'embarked', 'fare', 'home.dest', 'name', 'parch', 'pclass', 'sex', 'sibsp', 'survived', 'ticket']\n"
     ]
    }
   ],
   "source": [
    "train_df = _drop_unusable_cols(train_df, cols=['boat', 'body', 'train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['pclass',\n",
       "  'survived',\n",
       "  'name',\n",
       "  'sex',\n",
       "  'age',\n",
       "  'sibsp',\n",
       "  'parch',\n",
       "  'ticket',\n",
       "  'fare',\n",
       "  'cabin',\n",
       "  'embarked',\n",
       "  'home.dest'],\n",
       " ['pclass',\n",
       "  'survived',\n",
       "  'name',\n",
       "  'sex',\n",
       "  'age',\n",
       "  'sibsp',\n",
       "  'parch',\n",
       "  'ticket',\n",
       "  'fare',\n",
       "  'cabin',\n",
       "  'embarked',\n",
       "  'boat',\n",
       "  'body',\n",
       "  'home.dest',\n",
       "  'train'])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns, test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-10 02:01:39,114-__main__-INFO: Dropping the following 3 unusable columns:\n",
      "['boat', 'body', 'train']\n",
      "2019-12-10 02:01:39,129-__main__-INFO: Remaining 12 columns:\n",
      " ['age', 'cabin', 'embarked', 'fare', 'home.dest', 'name', 'parch', 'pclass', 'sex', 'sibsp', 'survived', 'ticket']\n"
     ]
    }
   ],
   "source": [
    "test_df = _drop_unusable_cols(test_df, cols=['boat', 'body', 'train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.withColumn('train_new', f.lit(True))\n",
    "test_df = test_df.withColumn('train_new', f.lit(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1309"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df = train_df.unionByName(test_df)\n",
    "joined_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-10 02:14:11,775-__main__-INFO: Dropping the following 2 unusable columns:\n",
      "['boat', 'body']\n",
      "2019-12-10 02:14:11,804-__main__-INFO: Remaining 13 columns:\n",
      " ['age', 'cabin', 'embarked', 'fare', 'home.dest', 'name', 'parch', 'pclass', 'sex', 'sibsp', 'survived', 'ticket', 'train']\n"
     ]
    }
   ],
   "source": [
    "df = _drop_unusable_cols(df_raw, cols=['boat', 'body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f960edf3588>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.select('survived').groupBy('survived').count().toPandas().set_index('survived').plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA y Ejercicio 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.heatmap(df[['survived', 'age', 'parch', 'fare', 'sibsp']].corr(),\n",
    "                annot=True, fmt = \".2f\", cmap = \"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(df, col='survived')\n",
    "g = g.map(sns.distplot, 'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.kdeplot(df['age'][(df['survived'] == 0) & \n",
    "                             (df['age'].notnull())], color='Red', shade = True)\n",
    "g = sns.kdeplot(df['age'][(df['survived'] == 1) & \n",
    "                             (df['age'].notnull())], color='Blue', shade = True)\n",
    "g.set_xlabel('age')\n",
    "g.set_ylabel('Frequency')\n",
    "g = g.legend(['Not Survived', 'Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['fare'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fare'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['fare'].fillna(df['fare'].mean()).isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuci√≥n de precio de boletos \n",
    "g = sns.distplot(df['fare'].fillna(df['fare'].mean()), color='m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['fare'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fare'] = df['fare'].map(lambda i: np.log(i) if i > 0 else 0)\n",
    "g = sns.distplot(df['fare'].fillna(df['fare'].mean()), color='m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.barplot(x='sex', y='survived', data=df)\n",
    "g = g.set_ylabel(\"Survival Probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['sex', 'survived']].groupby('sex').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.factorplot(x='pclass', y='survived', hue='sex', data=df,\n",
    "                   height=6, kind='bar')\n",
    "g = g.set_ylabels(\"survival probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4: Valores nulos y constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(df.isnull().mean() < 0.5).index.tolist()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _drop_nulls(df, max_null_prop=0.5):\n",
    "    logger.info(\n",
    "        f\"Dropping columns with null ratio greater than {max_null_prop * 100}%...\"\n",
    "    )\n",
    "    null_means = df.isnull().mean()\n",
    "    null_mask = null_means < max_null_prop\n",
    "    null_mask[[c for c in null_mask.index.tolist() if c in PROTECTED_COLS]] = True\n",
    "    drop_cols = null_mask[~null_mask].index.tolist()\n",
    "    logger.info(\n",
    "        f\"null proportions:\\n\"\n",
    "        f\"{null_means.loc[drop_cols].sort_values(ascending=False)}\"\n",
    "    )\n",
    "\n",
    "    logger.info(f\"Dropping the following {len(drop_cols)} columns:\\n {drop_cols}\")\n",
    "\n",
    "    df = df.drop(drop_cols, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROTECTED_COLS = ['survived', 'train']\n",
    "df = _drop_nulls(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _drop_std(df, min_std_dev=1.5e-2):\n",
    "    std_values = df.std()\n",
    "    low_variance_cols = std_values < min_std_dev\n",
    "    low_variance_cols = low_variance_cols.index[low_variance_cols].tolist()\n",
    "    low_variance_cols = [c for c in low_variance_cols if c not in PROTECTED_COLS]\n",
    "    logger.info(\n",
    "        f'Dropping the following {len(low_variance_cols)} columns '\n",
    "        f'due to low variance:\\n {low_variance_cols}'\n",
    "    )\n",
    "    df.drop(low_variance_cols, axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = _drop_std(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 1 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_typed_cols(df, col_type='cat'):\n",
    "    assert col_type in ('cat', 'num')\n",
    "    include = 'object' if col_type == 'cat' else [np.number]\n",
    "    typed_cols = [\n",
    "        c for c in df.select_dtypes(include=include).columns if c not in PROTECTED_COLS\n",
    "    ]\n",
    "    return typed_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_get_typed_cols(df, col_type='foo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = _get_typed_cols(df, col_type='num')\n",
    "cat_cols = _get_typed_cols(df, col_type='cat')\n",
    "num_cols, cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sex'].value_counts().index.to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fill_nulls(df):\n",
    "    for t in ['num', 'cat']:\n",
    "        cols = _get_typed_cols(df, col_type=t)\n",
    "        for c in cols:\n",
    "            if t == 'num':\n",
    "                df[c] = df[c].fillna(df[c].median())\n",
    "            else:\n",
    "                val_count = df[c].value_counts(dropna=True)\n",
    "                common_val = val_count.index.tolist()[0]\n",
    "                df[c] = df[c].fillna(common_val)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = _fill_nulls(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5: Ingenieria de Atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.name.str.split(',').str[-1].str.split('.').str[0].str.strip().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un nuevo atributo \"titulo\"\n",
    "df['title'] = df.name.str.split(',').str[-1].str.split('.').str[0].str.strip()\n",
    "df['title'] = df['title'].replace(\n",
    "    df.title.value_counts(dropna=False).index.tolist()[4:], 'other'\n",
    ")\n",
    "df['title'] = df['title'].replace(['Miss'], 'Mrs')\n",
    "df = df.drop(['name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.countplot(df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.factorplot(x='title',y='survived',data=df,kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['family_size'] = df['parch'] + df['sibsp'] + 1\n",
    "df['family_single'] = df['family_size'] == 1\n",
    "df['family_small'] = (df['family_size'] > 1) & (df['family_size'] <= 4)\n",
    "df['family_large'] = df['family_size'] > 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fsize in ['single', 'small', 'large']:\n",
    "    g = sns.factorplot(x=f'family_{fsize}',y='survived',data=df,kind=\"bar\")\n",
    "    g = g.set_ylabels(\"Survival Probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ticket.sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ticket prefix\n",
    "def extract_ticket_prefix(i):\n",
    "    if not i.isdigit() :\n",
    "        rv = i.replace('.',\"\").replace('/',\"\").strip().split(' ')[0]\n",
    "    else:\n",
    "        rv = 'X'\n",
    "    return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ticket'] = df['ticket'].apply(extract_ticket_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ticket.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 6: Fitteo de regresi√≥n logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['home.dest'].value_counts().index.values[0: 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _encode_categorical(df, top=20):\n",
    "    logger.info(\"Filtering categorical columns top values...\")\n",
    "    cat_cols = _get_typed_cols(df, col_type='cat')\n",
    "    logger.info(f\"Categorical columns:\\n {cat_cols}\")\n",
    "\n",
    "    for c in cat_cols:\n",
    "        top_categories = df[c].value_counts().index.values[0:top]\n",
    "        logger.info(f\"Top categories for {c}:\\n {top_categories}\")\n",
    "        df[c] = df[c].where(df[c].isin(top_categories), other='OTHER')\n",
    "\n",
    "    logger.info(\"Getting dummies from top categories...\")\n",
    "    df = pd.get_dummies(df, columns=cat_cols, drop_first=False)\n",
    "    logger.info(\n",
    "        f\"{len(df.columns)} columns after dummies:\\n \" f\"{sorted(df.columns.tolist())}\"\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = _encode_categorical(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df['train']]\n",
    "df_test = df[~df['train']]\n",
    "y_train = df_train['survived']\n",
    "y_test = df_test['survived']\n",
    "X_train = df_train.drop(['survived', 'train'], axis=1)\n",
    "X_test = df_test.drop(['survived', 'train'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'age' in X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "y_pred_proba = lr.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_score = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score = metrics.f1_score(y_test, y_pred)\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = metrics.classification_report(y_test, y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 7: √°rboles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeClassifier()\n",
    "dt = dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "y_pred_proba = dt.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.plot_tree(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=5, n_jobs=-1, verbose=2,)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "y_pred_proba = rf.predict_proba(X_test)[:, 1]\n",
    "print(rf.score(X_train, y_train))\n",
    "print(rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "feat_import = list(\n",
    "zip(np.asanyarray(X_train.columns)[indices], importances[indices])\n",
    ")\n",
    "feat_import = pd.DataFrame(feat_import, columns=['feature', 'importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = feat_import[:20].plot(kind='bar')\n",
    "ax.set_xticklabels(feat_import[:20]['feature'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
